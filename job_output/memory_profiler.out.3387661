/users/PAS2152/eashanvytla1/mamba-vla/.venv/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/users/PAS2152/eashanvytla1/mamba-vla/.venv/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
__      __ _                          _____   _____  _____             _______   _____  _    _ 
\ \    / /| |         /\             / ____| / ____||  __ \     /\    |__   __| / ____|| |  | |
 \ \  / / | |        /  \    ______ | (___  | |     | |__) |   /  \      | |   | |     | |__| |
  \ \/ /  | |       / /\ \  |______| \___ \ | |     |  _  /   / /\ \     | |   | |     |  __  |
   \  /   | |____  / ____ \          ____) || |____ | | \ \  / ____ \    | |   | |____ | |  | |
    \/    |______|/_/    \_\        |_____/  \_____||_|  \_\/_/    \_\   |_|    \_____||_|  |_|
                                                                                               
                                                                                               

 World size: 1
Device mesh: None
/users/PAS2152/eashanvytla1/mamba-vla/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
`torch_dtype` is deprecated! Use `dtype` instead!
The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation for mamba-ssm and install the kernels library using `pip install kernels` or https://github.com/Dao-AILab/causal-conv1d for causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [01:13<02:26, 73.48s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [02:25<01:12, 72.61s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [02:39<00:00, 45.63s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [02:39<00:00, 53.00s/it]
VLM model initialized in 164.74 seconds: MambaForCausalLM
Action expert initialized in 0.44 seconds.
[Rank 0] ðŸ”¥ Warmup pass...
Error executing job with overrides: ['policy=pi-mamba', 'data=calvin', 'batch_size=8', 'lr.base=5e-5', '+lr.action_expert=5e-5', 'profile_memory=True', 'wandb.mode=online']
Traceback (most recent call last):
  File "/users/PAS2152/eashanvytla1/mamba-vla/scripts/train_policy.py", line 199, in main
    loss, _ = policy.compute_loss(dummy_data)
  File "/users/PAS2152/eashanvytla1/mamba-vla/vla_scratch/policies/pi/policy.py", line 329, in compute_loss
    ce_loss, vlm_outputs, log_dict_prefix = self.encode_prefix(
  File "/users/PAS2152/eashanvytla1/mamba-vla/vla_scratch/policies/pi/policy.py", line 243, in encode_prefix
    ce_loss, vlm_outputs, log_dict = self.vlm_bridge.encode(
  File "/users/PAS2152/eashanvytla1/mamba-vla/vla_scratch/policies/modules/vlm_bridge/mamba/bridge.py", line 253, in encode
    pred_logits = self.causal_model.lm_head(text_hidden)
  File "/users/PAS2152/eashanvytla1/mamba-vla/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/PAS2152/eashanvytla1/mamba-vla/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/PAS2152/eashanvytla1/mamba-vla/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: expected scalar type BFloat16 but found Float

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[rank0]:[W128 11:47:35.763202712 ProcessGroupNCCL.cpp:1476] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
E0128 11:47:38.127000 3466099 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 3466110) of binary: /users/PAS2152/eashanvytla1/mamba-vla/.venv/bin/python3
Traceback (most recent call last):
  File "/users/PAS2152/eashanvytla1/mamba-vla/.venv/bin/torchrun", line 10, in <module>
    sys.exit(main())
  File "/users/PAS2152/eashanvytla1/mamba-vla/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/users/PAS2152/eashanvytla1/mamba-vla/.venv/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in main
    run(args)
  File "/users/PAS2152/eashanvytla1/mamba-vla/.venv/lib/python3.10/site-packages/torch/distributed/run.py", line 883, in run
    elastic_launch(
  File "/users/PAS2152/eashanvytla1/mamba-vla/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 139, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/users/PAS2152/eashanvytla1/mamba-vla/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 270, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
scripts/train_policy.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-01-28_11:47:38
  host      : a0328.ten.osc.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3466110)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
